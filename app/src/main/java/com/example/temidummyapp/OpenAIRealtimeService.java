package com.example.temidummyapp;

import android.media.AudioFormat;
import android.media.AudioRecord;
import android.media.AudioTrack;
import android.media.MediaRecorder;
import android.os.Handler;
import android.os.Looper;
import android.util.Base64;
import android.util.Log;

import com.google.gson.Gson;
import com.google.gson.JsonArray;
import com.google.gson.JsonObject;

import java.nio.ByteBuffer;
import java.nio.ByteOrder;
import java.util.concurrent.TimeUnit;

import okhttp3.OkHttpClient;
import okhttp3.Request;
import okhttp3.Response;
import okhttp3.WebSocket;
import okhttp3.WebSocketListener;
import okio.ByteString;

/**
 * OpenAI Realtime API ì„œë¹„ìŠ¤
 * WebSocketì„ í†µí•œ ì‹¤ì‹œê°„ ì–‘ë°©í–¥ ìŒì„± ëŒ€í™”
 */
public class OpenAIRealtimeService {
    private static final String TAG = "OpenAIRealtimeService";
    private static final String REALTIME_API_URL = "wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-10-01";

    // ì˜¤ë””ì˜¤ ì„¤ì •
    private static final int SAMPLE_RATE = 24000; // OpenAI Realtime API ìš”êµ¬ì‚¬í•­
    private static final int CHANNEL_CONFIG = AudioFormat.CHANNEL_IN_MONO;
    private static final int AUDIO_FORMAT = AudioFormat.ENCODING_PCM_16BIT;

    private final OkHttpClient client;
    private final Gson gson;
    private final Handler mainHandler;
    private final String apiKey;

    private WebSocket webSocket;
    private AudioRecord audioRecord;
    private AudioTrack audioTrack;
    private boolean isStreaming = false;
    private boolean isMicrophonePaused = false; // ë§ˆì´í¬ ì¼ì‹œ ì¤‘ì§€ ìƒíƒœ
    private RealtimeCallback callback;

    // ìŒì•• ê°ì§€
    private float currentAudioLevel = 0.0f;

    public interface RealtimeCallback {
        void onConnected();

        void onAudioLevelChanged(float level); // 0.0 ~ 1.0

        void onTranscriptReceived(String transcript);

        void onResponseStarted();

        void onResponseReceived(String response);

        void onResponseComplete();

        void onError(String error);

        void onDisconnected();
    }

    public OpenAIRealtimeService(String apiKey) {
        this.apiKey = apiKey;
        this.client = new OkHttpClient.Builder()
                .readTimeout(0, TimeUnit.MILLISECONDS)
                .build();
        this.gson = new Gson();
        this.mainHandler = new Handler(Looper.getMainLooper());
    }

    public void setCallback(RealtimeCallback callback) {
        this.callback = callback;
    }

    /**
     * Realtime API ì—°ê²°
     */
    public void connect() {
        Request request = new Request.Builder()
                .url(REALTIME_API_URL)
                .addHeader("Authorization", "Bearer " + apiKey)
                .addHeader("OpenAI-Beta", "realtime=v1")
                .build();

        webSocket = client.newWebSocket(request, new WebSocketListener() {
            @Override
            public void onOpen(WebSocket webSocket, Response response) {
                Log.d(TAG, "WebSocket ì—°ê²°ë¨");

                // ì„¸ì…˜ ì„¤ì • ì „ì†¡
                sendSessionUpdate();

                if (callback != null) {
                    mainHandler.post(callback::onConnected);
                }
            }

            @Override
            public void onMessage(WebSocket webSocket, String text) {
                handleTextMessage(text);
            }

            @Override
            public void onMessage(WebSocket webSocket, ByteString bytes) {
                handleBinaryMessage(bytes);
            }

            @Override
            public void onFailure(WebSocket webSocket, Throwable t, Response response) {
                Log.e(TAG, "WebSocket ì˜¤ë¥˜", t);
                if (callback != null) {
                    mainHandler.post(() -> callback.onError(t.getMessage()));
                }
            }

            @Override
            public void onClosed(WebSocket webSocket, int code, String reason) {
                Log.d(TAG, "WebSocket ì¢…ë£Œë¨: " + reason);
                if (callback != null) {
                    mainHandler.post(callback::onDisconnected);
                }
            }
        });
    }

    /**
     * ì„¸ì…˜ ì„¤ì • ì „ì†¡ (RAG ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ í¬í•¨)
     */
    private void sendSessionUpdate() {
        // OpenAIServiceì˜ SYSTEM_PROMPT ì¬ì‚¬ìš©
        String systemPrompt = getSystemPrompt();

        JsonObject sessionUpdate = new JsonObject();
        sessionUpdate.addProperty("type", "session.update");

        JsonObject session = new JsonObject();

        // ëª¨ë‹¬ë¦¬í‹° ì„¤ì • (í…ìŠ¤íŠ¸ + ì˜¤ë””ì˜¤) - ë°°ì—´ í˜•ì‹ìœ¼ë¡œ ì „ì†¡
        JsonArray modalities = new JsonArray();
        modalities.add("text");
        modalities.add("audio");
        session.add("modalities", modalities);

        // ìŒì„± ì„¤ì •
        session.addProperty("voice", "alloy"); // alloy, echo, fable, onyx, nova, shimmer

        // ì§€ì‹œì‚¬í•­ (RAG ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸)
        session.addProperty("instructions", systemPrompt);

        // ì…ë ¥ ì˜¤ë””ì˜¤ í˜•ì‹ - ë¬¸ìì—´ë¡œ ì „ì†¡
        session.addProperty("input_audio_format", "pcm16");

        // ì¶œë ¥ ì˜¤ë””ì˜¤ í˜•ì‹ - ë¬¸ìì—´ë¡œ ì „ì†¡
        session.addProperty("output_audio_format", "pcm16");

        // ì…ë ¥ ìŒì„± ì „ì‚¬ í™œì„±í™” (ì‚¬ìš©ì ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜)
        JsonObject inputAudioTranscription = new JsonObject();
        inputAudioTranscription.addProperty("model", "whisper-1");
        session.add("input_audio_transcription", inputAudioTranscription);

        // VAD (Voice Activity Detection) ì„¤ì •
        // thresholdë¥¼ ë†’ì—¬ì„œ í™•ì‹¤í•œ ìŒì„±ë§Œ ê°ì§€ (0.5 â†’ 0.8)
        // silence_durationì„ ëŠ˜ë ¤ì„œ ì‚¬ìš©ìê°€ ë§í•  ì‹œê°„ í™•ë³´ (500ms â†’ 2000ms)
        JsonObject turnDetection = new JsonObject();
        turnDetection.addProperty("type", "server_vad");
        turnDetection.addProperty("threshold", 0.8); // ë†’ì€ ë¯¼ê°ë„ (0.5 â†’ 0.8)
        turnDetection.addProperty("prefix_padding_ms", 500); // ë°œí™” ì‹œì‘ ì „ íŒ¨ë”© ì¦ê°€
        turnDetection.addProperty("silence_duration_ms", 2000); // 2ì´ˆ ì¹¨ë¬µ í›„ í„´ ì¢…ë£Œ (500ms â†’ 2000ms)
        session.add("turn_detection", turnDetection);

        sessionUpdate.add("session", session);

        String message = gson.toJson(sessionUpdate);
        webSocket.send(message);
        Log.d(TAG, "ì„¸ì…˜ ì„¤ì • ì „ì†¡ ì™„ë£Œ (RAG í¬í•¨)");
    }

    /**
     * OpenAIServiceì˜ SYSTEM_PROMPT ê°€ì ¸ì˜¤ê¸°
     */
    private String getSystemPrompt() {
        // OpenAIService ì¸ìŠ¤í„´ìŠ¤ë¥¼ í†µí•´ ê°€ì ¸ì˜¤ê¸°
        OpenAIService openAIService = new OpenAIService();
        return openAIService.getSystemPrompt();
    }

    /**
     * í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì²˜ë¦¬
     */
    private void handleTextMessage(String text) {
        try {
            JsonObject json = gson.fromJson(text, JsonObject.class);
            String type = json.has("type") ? json.get("type").getAsString() : "";

            Log.d(TAG, "ìˆ˜ì‹  ë©”ì‹œì§€ íƒ€ì…: " + type);

            switch (type) {
                case "session.created":
                case "session.updated":
                    Log.d(TAG, "ì„¸ì…˜ ì¤€ë¹„ë¨");
                    break;

                case "conversation.item.input_audio_transcription.completed":
                    // ì‚¬ìš©ì ìŒì„± ì¸ì‹ ê²°ê³¼
                    if (json.has("transcript")) {
                        String transcript = json.get("transcript").getAsString();
                        if (callback != null) {
                            mainHandler.post(() -> callback.onTranscriptReceived(transcript));
                        }
                    }
                    break;

                case "response.audio_transcript.delta":
                    // AI ì‘ë‹µ í…ìŠ¤íŠ¸ ìŠ¤íŠ¸ë¦¼
                    if (json.has("delta")) {
                        String delta = json.get("delta").getAsString();
                        if (callback != null) {
                            mainHandler.post(() -> callback.onResponseReceived(delta));
                        }
                    }
                    break;

                case "response.audio.delta":
                    // AI ìŒì„± ìŠ¤íŠ¸ë¦¼ (Base64 ì¸ì½”ë”©ëœ PCM16 ë°ì´í„°)
                    if (json.has("delta")) {
                        String audioBase64 = json.get("delta").getAsString();
                        playAudioChunk(audioBase64);
                    }
                    break;

                case "response.done":
                    // AI ì‘ë‹µ ì™„ë£Œ
                    if (callback != null) {
                        mainHandler.post(callback::onResponseComplete);
                    }
                    break;

                case "error":
                    // ì˜¤ë¥˜ ë°œìƒ
                    String error = json.has("error") ? json.get("error").toString() : "Unknown error";
                    if (callback != null) {
                        mainHandler.post(() -> callback.onError(error));
                    }
                    break;

                default:
                    Log.d(TAG, "ì²˜ë¦¬ë˜ì§€ ì•Šì€ ë©”ì‹œì§€ íƒ€ì…: " + type);
                    break;
            }
        } catch (Exception e) {
            Log.e(TAG, "ë©”ì‹œì§€ íŒŒì‹± ì˜¤ë¥˜", e);
        }
    }

    /**
     * ë°”ì´ë„ˆë¦¬ ë©”ì‹œì§€ ì²˜ë¦¬
     */
    private void handleBinaryMessage(ByteString bytes) {
        // ì˜¤ë””ì˜¤ ë°ì´í„° ì²˜ë¦¬
        Log.d(TAG, "ë°”ì´ë„ˆë¦¬ ë°ì´í„° ìˆ˜ì‹ : " + bytes.size() + " bytes");
    }

    /**
     * ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
     */
    public void startAudioStreaming() {
        if (isStreaming) {
            return;
        }

        isStreaming = true;

        new Thread(() -> {
            try {
                int bufferSize = AudioRecord.getMinBufferSize(SAMPLE_RATE, CHANNEL_CONFIG, AUDIO_FORMAT);
                audioRecord = new AudioRecord(MediaRecorder.AudioSource.MIC, SAMPLE_RATE, CHANNEL_CONFIG,
                        AUDIO_FORMAT, bufferSize);

                audioRecord.startRecording();
                Log.d(TAG, "ì˜¤ë””ì˜¤ ë…¹ìŒ ì‹œì‘");

                byte[] buffer = new byte[bufferSize];

                while (isStreaming) {
                    // ë§ˆì´í¬ê°€ ì¼ì‹œ ì¤‘ì§€ ìƒíƒœë©´ ë°ì´í„° ì½ì§€ë§Œ ì „ì†¡í•˜ì§€ ì•ŠìŒ
                    int bytesRead = audioRecord.read(buffer, 0, buffer.length);

                    if (bytesRead > 0 && !isMicrophonePaused) {
                        // ìŒì•• ê³„ì‚°
                        calculateAudioLevel(buffer, bytesRead);

                        // Base64 ì¸ì½”ë”©
                        String audioBase64 = Base64.encodeToString(buffer, 0, bytesRead, Base64.NO_WRAP);

                        // WebSocketìœ¼ë¡œ ì „ì†¡ (ë§ˆì´í¬ ì¼ì‹œ ì¤‘ì§€ ìƒíƒœê°€ ì•„ë‹ ë•Œë§Œ)
                        JsonObject audioAppend = new JsonObject();
                        audioAppend.addProperty("type", "input_audio_buffer.append");
                        audioAppend.addProperty("audio", audioBase64);

                        webSocket.send(gson.toJson(audioAppend));
                    } else if (isMicrophonePaused) {
                        // ì¼ì‹œ ì¤‘ì§€ ì¤‘ì—ëŠ” ìŒì•• ë ˆë²¨ 0ìœ¼ë¡œ ì„¤ì •
                        currentAudioLevel = 0.0f;
                        if (callback != null) {
                            mainHandler.post(() -> callback.onAudioLevelChanged(0.0f));
                        }
                    }
                }
            } catch (Exception e) {
                Log.e(TAG, "ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜", e);
                if (callback != null) {
                    mainHandler.post(() -> callback.onError("ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜: " + e.getMessage()));
                }
            }
        }).start();
    }

    /**
     * ìŒì•• ê³„ì‚° (0.0 ~ 1.0)
     */
    private void calculateAudioLevel(byte[] buffer, int length) {
        if (length == 0) {
            currentAudioLevel = 0.0f;
            return;
        }

        // PCM16 ë°ì´í„°ë¥¼ shortë¡œ ë³€í™˜í•˜ì—¬ RMS ê³„ì‚°
        long sum = 0;
        int sampleCount = length / 2;

        for (int i = 0; i < length - 1; i += 2) {
            short sample = (short) ((buffer[i + 1] << 8) | (buffer[i] & 0xFF));
            sum += sample * sample;
        }

        double rms = Math.sqrt((double) sum / sampleCount);
        double db = 20 * Math.log10(rms / 32768.0); // -60dB ~ 0dB ë²”ìœ„

        // 0.0 ~ 1.0ìœ¼ë¡œ ì •ê·œí™” (-60dB ~ 0dB -> 0.0 ~ 1.0)
        float normalizedLevel = (float) Math.max(0.0, Math.min(1.0, (db + 60) / 60));

        // ë¶€ë“œëŸ¬ìš´ ì „í™˜
        currentAudioLevel = currentAudioLevel * 0.7f + normalizedLevel * 0.3f;

        if (callback != null) {
            mainHandler.post(() -> callback.onAudioLevelChanged(currentAudioLevel));
        }
    }

    /**
     * AI ìŒì„± ì¬ìƒ
     */
    private void playAudioChunk(String audioBase64) {
        try {
            byte[] audioData = Base64.decode(audioBase64, Base64.NO_WRAP);

            if (audioTrack == null) {
                int bufferSize = AudioTrack.getMinBufferSize(SAMPLE_RATE,
                        AudioFormat.CHANNEL_OUT_MONO, AUDIO_FORMAT);

                audioTrack = new AudioTrack(
                        android.media.AudioManager.STREAM_MUSIC,
                        SAMPLE_RATE,
                        AudioFormat.CHANNEL_OUT_MONO,
                        AUDIO_FORMAT,
                        bufferSize,
                        AudioTrack.MODE_STREAM);

                audioTrack.play();
            }

            audioTrack.write(audioData, 0, audioData.length);
        } catch (Exception e) {
            Log.e(TAG, "ì˜¤ë””ì˜¤ ì¬ìƒ ì˜¤ë¥˜", e);
        }
    }

    /**
     * ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€ (ìˆœì°¨ì  ì¢…ë£Œ)
     */
    public void stopAudioStreaming() {
        Log.d(TAG, "ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€ ì‹œì‘");
        
        // 1. ìŠ¤íŠ¸ë¦¬ë° í”Œë˜ê·¸ ë„ê¸° (ë…¹ìŒ ë£¨í”„ ì¤‘ë‹¨)
        isStreaming = false;

        // 2. ì˜¤ë””ì˜¤ ì¬ìƒ ì¤‘ì§€ (ì§„í–‰ ì¤‘ì¸ ì¶œë ¥ ì¦‰ì‹œ ì¤‘ë‹¨)
        if (audioTrack != null) {
            try {
                Log.d(TAG, "AudioTrack ì¤‘ì§€ ì‹œì‘");
                
                // ì¬ìƒ ì¤‘ì¸ ì˜¤ë””ì˜¤ ì¦‰ì‹œ í”ŒëŸ¬ì‹œ
                audioTrack.pause();
                audioTrack.flush();
                audioTrack.stop();
                audioTrack.release();
                audioTrack = null;
                
                Log.d(TAG, "AudioTrack ì¤‘ì§€ ì™„ë£Œ");
            } catch (IllegalStateException e) {
                Log.w(TAG, "AudioTrackì´ ì´ë¯¸ í•´ì œë¨", e);
            } catch (Exception e) {
                Log.e(TAG, "AudioTrack ì¤‘ì§€ ì˜¤ë¥˜", e);
            }
        }

        // 3. ì˜¤ë””ì˜¤ ë…¹ìŒ ì¤‘ì§€
        if (audioRecord != null) {
            try {
                Log.d(TAG, "AudioRecord ì¤‘ì§€ ì‹œì‘");
                
                // ë…¹ìŒ ìƒíƒœ í™•ì¸ í›„ ì¤‘ì§€
                if (audioRecord.getRecordingState() == AudioRecord.RECORDSTATE_RECORDING) {
                    audioRecord.stop();
                }
                audioRecord.release();
                audioRecord = null;
                
                Log.d(TAG, "AudioRecord ì¤‘ì§€ ì™„ë£Œ");
            } catch (IllegalStateException e) {
                Log.w(TAG, "AudioRecordê°€ ì´ë¯¸ í•´ì œë¨", e);
            } catch (Exception e) {
                Log.e(TAG, "AudioRecord ì¤‘ì§€ ì˜¤ë¥˜", e);
            }
        }

        // 4. ìŒì•• ë ˆë²¨ ì´ˆê¸°í™”
        currentAudioLevel = 0.0f;
        
        Log.d(TAG, "ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€ ì™„ë£Œ");
    }

    /**
     * WebSocket ì—°ê²° ì¢…ë£Œ (ìˆœì°¨ì  ì¢…ë£Œ)
     */
    public void disconnect() {
        Log.d(TAG, "WebSocket ì—°ê²° ì¢…ë£Œ ì‹œì‘");
        
        // 1. ì˜¤ë””ì˜¤ ë¨¼ì € ì¤‘ì§€
        stopAudioStreaming();

        // 2. WebSocket ì¢…ë£Œ
        if (webSocket != null) {
            try {
                Log.d(TAG, "WebSocket close í˜¸ì¶œ");
                webSocket.close(1000, "ì •ìƒ ì¢…ë£Œ");
                webSocket = null;
                Log.d(TAG, "WebSocket ì¢…ë£Œ ì™„ë£Œ");
            } catch (Exception e) {
                Log.e(TAG, "WebSocket ì¢…ë£Œ ì˜¤ë¥˜", e);
                webSocket = null; // ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ nullë¡œ ì„¤ì •
            }
        }

        // 3. OkHttp ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        try {
            client.dispatcher().executorService().shutdown();
            Log.d(TAG, "OkHttp ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ");
        } catch (Exception e) {
            Log.e(TAG, "OkHttp ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì˜¤ë¥˜", e);
        }
        
        Log.d(TAG, "WebSocket ì—°ê²° ì¢…ë£Œ ì™„ë£Œ");
    }

    /**
     * ë§ˆì´í¬ ì¼ì‹œ ì¤‘ì§€ (AIê°€ ë§í•  ë•Œ - ì—ì½” ë°©ì§€)
     */
    public void pauseMicrophone() {
        if (!isMicrophonePaused && isStreaming) {
            isMicrophonePaused = true;
            Log.d(TAG, "ğŸ”‡ ë§ˆì´í¬ ì¼ì‹œ ì¤‘ì§€ (AI ì‘ë‹µ ì¤‘ - ì—ì½” ë°©ì§€)");
        }
    }

    /**
     * ë§ˆì´í¬ ì¬ê°œ (AIê°€ ë§ ëë‚¬ì„ ë•Œ)
     */
    public void resumeMicrophone() {
        if (isMicrophonePaused && isStreaming) {
            isMicrophonePaused = false;
            Log.d(TAG, "ğŸ¤ ë§ˆì´í¬ ì¬ê°œ (ì‚¬ìš©ì ì…ë ¥ ëŒ€ê¸°)");
        }
    }
}

